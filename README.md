ğŸ“„ Enterprise GenAI RAG (FastAPI + FAISS + BM25 + Hybrid) + MLflow Monitoring

Enterprise-ready Retrieval Augmented Generation (RAG) system built with:

âœ… FastAPI backend for upload + Q&A
âœ… PDF ingestion + chunking
âœ… FAISS semantic retrieval (Sentence Transformers)
âœ… BM25 keyword retrieval
âœ… Hybrid retrieval (FAISS + BM25 combined)
âœ… Flan-T5 LLM answer generation
âœ… MLflow monitoring + evaluation + A/B testing
âœ… Streamlit UI for chat

ğŸš€ Features
âœ… Document Ingestion

Upload any PDF document

Extract and clean text (fix broken words, remove extra spaces)

Chunk the text with overlap for better retrieval quality

âœ… Retrieval Options

You can query using 3 retriever modes:

Retriever	Type	Best For
faiss	Semantic	Meaning-based search
bm25	Keyword	Exact matching search
hybrid	Combined	Best overall performance
âœ… Answer Generation

Uses google/flan-t5-base

Generates short + clean answers

Falls back safely if context missing

âœ… MLflow Monitoring & Evaluation

Logs metrics like:

recall_at_5

faithfulness

hallucination_rate

latency_sec

Supports:

RAG evaluation pipeline

A/B evaluation for multiple retrievers

ğŸ“‚ Project Structure
enterprise-genai-rag/
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ api/
â”‚   â”‚   â”œâ”€â”€ main.py
â”‚   â”‚   â”œâ”€â”€ routes.py
â”‚   â”‚   â””â”€â”€ __init__.py
â”‚   â”‚
â”‚   â”œâ”€â”€ ingestion/
â”‚   â”‚   â”œâ”€â”€ pdf_loader.py
â”‚   â”‚   â”œâ”€â”€ chunker.py
â”‚   â”‚   â””â”€â”€ __init__.py
â”‚   â”‚
â”‚   â”œâ”€â”€ embeddings/
â”‚   â”‚   â”œâ”€â”€ embedder.py
â”‚   â”‚   â”œâ”€â”€ index_manager.py
â”‚   â”‚   â””â”€â”€ __init__.py
â”‚   â”‚
â”‚   â”œâ”€â”€ retrieval/
â”‚   â”‚   â”œâ”€â”€ retriever.py
â”‚   â”‚   â”œâ”€â”€ bm25_retriever.py
â”‚   â”‚   â”œâ”€â”€ hybrid_retriever.py
â”‚   â”‚   â”œâ”€â”€ router.py
â”‚   â”‚   â””â”€â”€ __init__.py
â”‚   â”‚
â”‚   â”œâ”€â”€ llm/
â”‚   â”‚   â”œâ”€â”€ generator.py
â”‚   â”‚   â””â”€â”€ __init__.py
â”‚   â”‚
â”‚   â”œâ”€â”€ utils/
â”‚   â”‚   â””â”€â”€ text.py
â”‚   â”‚
â”‚   â””â”€â”€ __init__.py
â”‚
â”œâ”€â”€ mlops/
â”‚   â”œâ”€â”€ evaluation/
â”‚   â”‚   â”œâ”€â”€ run_eval.py
â”‚   â”‚   â”œâ”€â”€ run_ab_eval.py
â”‚   â”‚   â”œâ”€â”€ build_bm25.py
â”‚   â”‚   â”œâ”€â”€ metrics.py
â”‚   â”‚   â””â”€â”€ __init__.py
â”‚   â”‚
â”‚   â”œâ”€â”€ mlflow/
â”‚   â”‚   â”œâ”€â”€ monitoring.py
â”‚   â”‚   â”œâ”€â”€ utils.py
â”‚   â”‚   â””â”€â”€ __init__.py
â”‚   â”‚
â”‚   â”œâ”€â”€ mlflow_logger.py
â”‚   â””â”€â”€ __init__.py
â”‚
â”œâ”€â”€ ui/
â”‚   â””â”€â”€ app.py
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ documents/
â”‚   â”œâ”€â”€ bm25/
â”‚   â””â”€â”€ eval/questions.json
â”‚
â”œâ”€â”€ vector_store/
â”‚   â””â”€â”€ (faiss index saved here)
â”‚
â”œâ”€â”€ mlflow.db
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md

âš™ï¸ Setup Instructions
âœ… 1) Clone Repository
git clone https://github.com/Subhajitdas99/enterprise-genai-rag.git
cd enterprise-genai-rag

âœ… 2) Create Virtual Environment
python -m venv .venv
.\.venv\Scripts\activate

âœ… 3) Install Dependencies
pip install -r requirements.txt

â–¶ï¸ Run FastAPI Server

Start the API:

uvicorn src.api.main:app --reload


Now open Swagger Docs:

âœ… http://127.0.0.1:8000/docs

ğŸ“¤ Upload PDF
Endpoint

POST /upload

Upload a PDF file through Swagger UI or Streamlit UI.

âœ… Response:

{
  "status": "indexed",
  "file": "yourfile.pdf"
}

â“ Ask Questions (RAG)
Endpoint

GET /ask

Example:

http://127.0.0.1:8000/ask?query=What%20is%20the%20registration%20date%3F&retriever_type=faiss

Query Params
Param	Description
query	User question
retriever_type	faiss / bm25 / hybrid

âœ… Response example:

{
  "answer": "...",
  "sources": [
    {
      "page": 1,
      "text": "...",
      "score": 1.62,
      "source": "faiss"
    }
  ],
  "retriever": "faiss"
}

ğŸ–¥ï¸ Run Streamlit UI
streamlit run ui/app.py

Open:
âœ… http://localhost:8501
ğŸ“Š MLflow Monitoring
âœ… Start MLflow UI

mlflow ui --workers 1

Open:
âœ… http://127.0.0.1:5000
âœ… Build BM25 Index (Required for BM25 / Hybrid)

Run:

python -m mlops.evaluation.build_bm25

âœ… Output:

âœ… BM25 index built successfully

This creates:

data/bm25/docs.pkl
data/bm25/bm25.pkl

âœ… RAG Evaluation (Single Retriever)

Runs evaluation using your dataset:

python -m mlops.evaluation.run_eval


Metrics logged to MLflow:
âœ… recall_at_5
âœ… faithfulness
âœ… latency_sec
âœ… hallucination_rate

âœ… A/B Evaluation (FAISS vs BM25 vs Hybrid)

Run:

python -m mlops.evaluation.run_ab_eval


This will create multiple MLflow runs:
âœ… retriever=faiss
âœ… retriever=bm25
âœ… retriever=hybrid

âœ… RAG Evaluation (Single Retriever)

Runs evaluation using your dataset:

python -m mlops.evaluation.run_eval


Metrics logged to MLflow:
âœ… recall_at_5
âœ… faithfulness
âœ… latency_sec
âœ… hallucination_rate

ğŸ“Œ Notes / Troubleshooting
âœ… HuggingFace timeouts

If model loads slow, run once manually:
python -c "from sentence_transformers import SentenceTransformer; SentenceTransformer('all-MiniLM-L6-v2')"
âœ… Page file / memory error (Windows)

If you see:
paging file too small
âœ… Increase Virtual Memory in Windows settings.

âœ… Future Improvements (Next Steps)

â­ Add reranker (CrossEncoder)
â­ Store embeddings in a DB (Chroma / Qdrant)
â­ Add conversation memory (chat history RAG)
â­ Add Docker support
â­ Add CI/CD pipeline + GitHub Actions
â­ Add proper eval dataset + leaderboard

ğŸ‘¨â€ğŸ’»Author
Subhajit Das
https://github.com/Subhajitdas99/enterprise-genai-rag
